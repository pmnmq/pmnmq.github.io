<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>pandas - 标签 - pujic</title><link>http://example.org/tags/pandas/</link><description>pandas - 标签 - pujic</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>pujichun@outlook.com (普吉春)</managingEditor><webMaster>pujichun@outlook.com (普吉春)</webMaster><lastBuildDate>Sun, 21 Mar 2021 19:08:35 +0000</lastBuildDate><atom:link href="http://example.org/tags/pandas/" rel="self" type="application/rss+xml"/><item><title>pandas数据描述性分析</title><link>http://example.org/posts/pandas%E6%95%B0%E6%8D%AE%E6%8F%8F%E8%BF%B0%E6%80%A7%E5%88%86%E6%9E%90/</link><pubDate>Sun, 21 Mar 2021 19:08:35 +0000</pubDate><author>作者</author><guid>http://example.org/posts/pandas%E6%95%B0%E6%8D%AE%E6%8F%8F%E8%BF%B0%E6%80%A7%E5%88%86%E6%9E%90/</guid><description>&lt;p>我们在几乎所有的数据处理场景中，用pandas将数据读入内存之后要做的第一件事都是查看数据的描述&lt;/p></description></item><item><title>时间序列数据处理</title><link>http://example.org/posts/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</link><pubDate>Fri, 19 Mar 2021 23:55:47 +0000</pubDate><author>作者</author><guid>http://example.org/posts/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</guid><description>&lt;p>在数据处理的时候经常会遇到时间序列数据，笔者有幸在4次竞赛6次集训中遇到过7次时序型数据，其中竞赛中有2次需要对数据进行聚合，集训中有2次需要对数据进行聚合。&lt;/p></description></item><item><title>pandas数据分组聚合</title><link>http://example.org/posts/pandas%E6%95%B0%E6%8D%AE%E8%81%9A%E5%90%88/</link><pubDate>Sat, 13 Mar 2021 11:25:24 +0000</pubDate><author>作者</author><guid>http://example.org/posts/pandas%E6%95%B0%E6%8D%AE%E8%81%9A%E5%90%88/</guid><description>&lt;p>数据分组聚合在数据分析中是经常出现的一个问题，分组之后往往伴随着聚合，但偶尔分组也会被用来做数据筛选，但是通过分组做数据筛选的方法肯定不是很好的筛选方法&lt;/p></description></item><item><title>pandas读取大文件筛选数据</title><link>http://example.org/posts/pandas%E8%AF%BB%E5%8F%96%E5%A4%A7%E6%96%87%E4%BB%B6%E7%AD%9B%E9%80%89%E6%95%B0%E6%8D%AE/</link><pubDate>Tue, 09 Mar 2021 10:30:04 +0000</pubDate><author>作者</author><guid>http://example.org/posts/pandas%E8%AF%BB%E5%8F%96%E5%A4%A7%E6%96%87%E4%BB%B6%E7%AD%9B%E9%80%89%E6%95%B0%E6%8D%AE/</guid><description>&lt;p>在参加某比赛的时候遇到过给出的训练数据集大小达到近9个G的&lt;code>csv&lt;/code>文件，但是这9个G的数据中的数据不一定都是我需要的，我需要对文件进行筛选。这样的情况需要将数据都读进内存中，如果内存够大，那么完全没问题（我尝试过至少要32G），这样一次性全量读取数据集并且操纵这个数据集对电脑的要求是比较高的，那么这时候我们可以使用分块读取数据。&lt;/p></description></item></channel></rss>