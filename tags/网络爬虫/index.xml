<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>网络爬虫 - 标签 - pmnmq</title><link>http://example.org/tags/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/</link><description>网络爬虫 - 标签 - pmnmq</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>pujichun@outlook.com (普吉春)</managingEditor><webMaster>pujichun@outlook.com (普吉春)</webMaster><lastBuildDate>Wed, 28 Oct 2020 12:21:50 +0000</lastBuildDate><atom:link href="http://example.org/tags/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/" rel="self" type="application/rss+xml"/><item><title>异步爬取必应壁纸</title><link>http://example.org/posts/%E5%BC%82%E6%AD%A5%E7%88%AC%E5%8F%96%E5%BF%85%E5%BA%94%E5%A3%81%E7%BA%B8/</link><pubDate>Wed, 28 Oct 2020 12:21:50 +0000</pubDate><author>作者</author><guid>http://example.org/posts/%E5%BC%82%E6%AD%A5%E7%88%AC%E5%8F%96%E5%BF%85%E5%BA%94%E5%A3%81%E7%BA%B8/</guid><description>&lt;p>异步高并发爬取必应壁纸下载链接，写入数据库后再异步下载存储图片&lt;/p></description></item><item><title>有道翻译web端js逆向</title><link>http://example.org/posts/%E6%9C%89%E9%81%93%E7%BF%BB%E8%AF%91web%E7%AB%AFjs%E9%80%86%E5%90%91/</link><pubDate>Sat, 01 Aug 2020 00:03:34 +0000</pubDate><author>作者</author><guid>http://example.org/posts/%E6%9C%89%E9%81%93%E7%BF%BB%E8%AF%91web%E7%AB%AFjs%E9%80%86%E5%90%91/</guid><description>&lt;p>网站url: &lt;a href="http://fanyi.youdao.com/" target="_blank" rel="noopener noreffer">http://fanyi.youdao.com/&lt;/a>&lt;/p></description></item><item><title>爬取猫眼电影票房</title><link>http://example.org/posts/%E7%88%AC%E5%8F%96%E7%8C%AB%E7%9C%BC%E7%94%B5%E5%BD%B1%E7%A5%A8%E6%88%BF/</link><pubDate>Fri, 31 Jul 2020 23:04:05 +0000</pubDate><author>作者</author><guid>http://example.org/posts/%E7%88%AC%E5%8F%96%E7%8C%AB%E7%9C%BC%E7%94%B5%E5%BD%B1%E7%A5%A8%E6%88%BF/</guid><description><![CDATA[<p>网站url: <a href="https://piaofang.maoyan.com/rankings/year?year=2020&amp;limit=100&amp;tab=1" target="_blank" rel="noopener noreffer">https://piaofang.maoyan.com/rankings/year?year=2020&limit=100&tab=1</a></p>
<p>初看网站的html发现有字体反爬虫，但是经过多次抓包之后发现除了第一次请求页面有字体反爬虫之外，其它几个年份并没有</p>
<p>而且第一次请求的年分的数据也可以通过api请求到</p>]]></description></item><item><title>对称加密-AES加密</title><link>http://example.org/posts/%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86-aes%E5%8A%A0%E5%AF%86/</link><pubDate>Wed, 22 Jul 2020 17:57:59 +0800</pubDate><author>作者</author><guid>http://example.org/posts/%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86-aes%E5%8A%A0%E5%AF%86/</guid><description>&lt;p>AES解密&lt;/p></description></item><item><title>xpath基本语法</title><link>http://example.org/posts/xpath%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/</link><pubDate>Thu, 26 Mar 2020 21:19:25 +0000</pubDate><author>作者</author><guid>http://example.org/posts/xpath%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/</guid><description><![CDATA[<p><strong>XPath</strong>即为XML路径语言（XML Path Language），它是一种用来确定XML文档中某部分位置的语言。</p>
<p>XPath基于XML的树状结构，提供在数据结构树中找寻节点的能力。</p>]]></description></item><item><title>Scrapy使用笔记</title><link>http://example.org/posts/scrapy%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</link><pubDate>Sat, 14 Mar 2020 00:22:14 +0000</pubDate><author>作者</author><guid>http://example.org/posts/scrapy%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</guid><description>&lt;p>Scrapy的中文文档似乎也和许多文档一样，在中文翻译上、内容上以及版本上存在很多的问题&lt;/p></description></item><item><title>requests快速上手</title><link>http://example.org/posts/requests%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</link><pubDate>Mon, 02 Mar 2020 11:33:12 +0800</pubDate><author>作者</author><guid>http://example.org/posts/requests%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</guid><description><![CDATA[<p><strong>Requests http for humans</strong></p>
<p>使用urllib库的时候可能会被各种编码、Handler、Opener弄得头大，有时候要构造一个请求需要的繁琐的步骤也是让人感觉十分繁琐</p>
<p>requests是Python实现的最简单易用的第三方HTTP请求库，充分体现了Python的简洁与优雅</p>
<p>requests官方文档：https://requests.readthedocs.io/en/latest/</p>]]></description></item><item><title>关于网络爬虫</title><link>http://example.org/posts/%E5%85%B3%E4%BA%8E%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/</link><pubDate>Sun, 01 Mar 2020 22:49:49 +0000</pubDate><author>作者</author><guid>http://example.org/posts/%E5%85%B3%E4%BA%8E%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/</guid><description>&lt;p>网络爬虫分为通用爬虫和聚焦爬虫&lt;/p></description></item><item><title>urllib库基本使用</title><link>http://example.org/posts/urllib%E5%BA%93%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</link><pubDate>Sun, 01 Mar 2020 17:24:57 +0000</pubDate><author>作者</author><guid>http://example.org/posts/urllib%E5%BA%93%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</guid><description>&lt;p>在Python中，要发起一个请求获取服务器的响应，我们不需要去关心计算机怎么去发起的这个请求，更不需要知道计算机底层是怎样实现的这个通信，我们只需要关注我们的这个请求的URL、参数、等等的信息，而这一切Python标准库中的urllib库已经为我们准备好了&lt;/p></description></item></channel></rss>